# KI-Service Integrationsanleitung

Dieses Dokument erkl√§rt wie man die verschiedenen KI-Services in der Application konfiguriert und nutzt.

## üéØ √úbersicht der unterst√ºtzten Services

Die Application unterst√ºtzt 5 verschiedene KI-Service Provider:

| Service | Kostenlos | Offline | Modelle | Setup-Schwierigkeit |
|---------|-----------|---------|---------|---------------------|
| **OpenAI** | ‚ùå Nach Credits | ‚ùå Nein | GPT-4, GPT-3.5 | ‚≠ê‚≠ê Mittel |
| **Claude** | ‚ùå Nach Credits | ‚ùå Nein | Claude 3 Opus/Sonnet | ‚≠ê‚≠ê Mittel |
| **Gemini** | ‚úÖ (Limits) | ‚ùå Nein | Gemini Pro | ‚≠ê‚≠ê Mittel |
| **Ollama** | ‚úÖ | ‚úÖ Ja | Llama, Mistral, etc. | ‚≠ê‚≠ê‚≠ê Schwer |
| **Lokal** | ‚úÖ | ‚úÖ Ja | Echo (Demo) | ‚≠ê Leicht |

---

## 1Ô∏è‚É£ OpenAI Integration

### Setup-Schritte

1. **API-Schl√ºssel besorgen:**
   - Gehe zu [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
   - Melde dich mit deinem OpenAI-Konto an
   - Klicke auf "Create new secret key +"
   - Kopiere den Schl√ºssel (wird nur einmal angezeigt!)

2. **In der App eingeben:**
   - √ñffne die Chat-Einstellungen (‚öôÔ∏è Icon)
   - W√§hle "OpenAI" aus dem KI-Service Dropdown
   - Klicke auf "API-Schl√ºssel eingeben"
   - Paste deinen Schl√ºssel
   - W√§hle ein Modell: `gpt-4-turbo` oder `gpt-3.5-turbo`

3. **Testen:**
   - Schreibe eine einfache Frage
   - Sollte eine Antwort innerhalb von 5-10 Sekunden kommen

### Modelle

| Modell | Performance | Kosten | Context | Empfohlen f√ºr |
|--------|-------------|--------|---------|---------------|
| **GPT-4 Turbo** | üî• Sehr hoch | $$$ | 128K tokens | Komplexe Aufgaben, Code |
| **GPT-4** | üî• Sehr hoch | $$$$ | 8K tokens | Hochwertige Antworten |
| **GPT-3.5 Turbo** | ‚úÖ Gut | $ | 4K tokens | Schnelle Antworten, Budget |

### Pricing

```
GPT-4 Turbo:
  - Input: $0.01 / 1K tokens
  - Output: $0.03 / 1K tokens
  
GPT-3.5 Turbo:
  - Input: $0.0005 / 1K tokens  
  - Output: $0.0015 / 1K tokens
```

### Troubleshooting

| Problem | L√∂sung |
|---------|--------|
| "Invalid API key" | Pr√ºfe ob Schl√ºssel korrekt kopiert wurde (keine Leerzeichen!) |
| "Rate limit exceeded" | Warte 1 Minute, dann versuche es erneut |
| Timeout nach 30s | OpenAI √ºberlastet, versuche sp√§ter oder wechsle zu GPT-3.5 |

---

## 2Ô∏è‚É£ Anthropic Claude Integration

### Setup-Schritte

1. **API-Schl√ºssel besorgen:**
   - Gehe zu [https://console.anthropic.com/account/keys](https://console.anthropic.com/account/keys)
   - Melde dich mit deinem Anthropic-Konto an
   - Klicke auf "Create Key"
   - Kopiere den Schl√ºssel

2. **In der App eingeben:**
   - Chat-Einstellungen (‚öôÔ∏è)
   - W√§hle "Anthropic Claude" aus
   - API-Schl√ºssel eingeben
   - W√§hle Claude 3 Opus oder Sonnet

3. **Kostenlose Credits:**
   - Neue Accounts bekommen $5 Credits
   - G√ºltig f√ºr 3 Monate

### Modelle

| Modell | Performance | Kosten | Context | Use Case |
|--------|-------------|--------|---------|----------|
| **Claude 3 Opus** | üî• Top | $$ | 200K tokens | Beste Qualit√§t |
| **Claude 3 Sonnet** | ‚úÖ Gut | $ | 200K tokens | Balanced |
| **Claude 3 Haiku** | ‚ö° Schnell | $ | 200K tokens | Schnelle Antworten |

### Pricing

```
Claude 3 Opus:
  - Input: $0.015 / 1K tokens
  - Output: $0.075 / 1K tokens
  
Claude 3 Sonnet:
  - Input: $0.003 / 1K tokens
  - Output: $0.015 / 1K tokens
```

### Besonderheiten

- Sehr lange Context-Fenster (200K tokens)
- Exzellente Code-Analyse
- Starke Compliance/Sicherheit

---

## 3Ô∏è‚É£ Google Gemini Integration

### Setup-Schritte

1. **API-Schl√ºssel besorgen:**
   - Gehe zu [https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)
   - Klicke auf "Create API key"
   - W√§hle dein Google-Project
   - Kopiere den Schl√ºssel

2. **In der App eingeben:**
   - Chat-Einstellungen
   - W√§hle "Google Gemini" aus
   - API-Schl√ºssel eingeben
   - Model: `gemini-pro`

3. **Kostenlos testen:**
   - Bis zu 60 API-Anfragen pro Minute (kostenlos)
   - Keine Kreditkarte n√∂tig!

### Modelle

| Modell | Performance | Erkenntnisse |
|--------|-------------|-------------|
| **Gemini Pro** | ‚úÖ Gut | Multimodal-ready (Bilder bald) |

### Pricing

```
Gemini Pro (Free):
  - 60 calls/min (kostenlos)
  - Danach: $0.00025 / 1K input tokens
```

---

## 4Ô∏è‚É£ Ollama (Local LLMs)

### Was ist Ollama?

Ollama ist eine Open-Source Software zum lokalen Ausf√ºhren von LLMs. **Kein Internet n√∂tig, keine Kosten, vollst√§ndige Privatsph√§re.**

### Installation

1. **Ollama installieren:**
   - Gehe zu [https://ollama.ai](https://ollama.ai)
   - Lade Version f√ºr Windows/Mac/Linux herunter
   - Installiere und starte die Anwendung

2. **Ein Modell laden:**
   ```bash
   # Terminal/Powershell √∂ffnen
   ollama pull llama2
   # Oder andere Modelle:
   # ollama pull mistral
   # ollama pull neural-chat
   ```

3. **Ollama Server starten:**
   ```bash
   ollama serve
   # Server l√§uft dann auf http://localhost:11434
   ```

4. **In der App verwenden:**
   - Chat-Einstellungen
   - W√§hle "Ollama (Lokal)" aus
   - API-URL: `http://localhost:11434` (Standard)
   - Modell: `llama2` (oder dein geladenes Modell)
   - Fertig! Tippe deine Nachricht

### Verf√ºgbare Modelle

| Modell | Gr√∂√üe | Speed | Qualit√§t | VRAM ben√∂tigt |
|--------|-------|-------|----------|---------------|
| **Llama 2** | 7B | ‚ö°‚ö° | ‚úÖ Gut | 8 GB |
| **Mistral** | 7B | ‚ö°‚ö°‚ö° | ‚úÖ Sehr Gut | 8 GB |
| **Neural Chat** | 7B | ‚ö°‚ö° | ‚úÖ Spezialisiert | 8 GB |
| **Llama 2 13B** | 13B | ‚ö° | üî• Besser | 16 GB |

### Systemanforderungen

- **RAM:** Minimum 8 GB (besser 16 GB)
- **VRAM:** F√ºr GPU-Beschleunigung (optional)
- **Disk:** 5-10 GB pro Modell

### Vorteile

‚úÖ Kostenlos  
‚úÖ Offline (keine Netzwerkabh√§ngigkeit)  
‚úÖ Privat (keine Daten verlassen deinen Rechner)  
‚úÖ Keine API-Keys n√∂tig  
‚úÖ Unbegrenzte Nutzung  

### Nachteile

‚ùå Langsamer als Cloud-Services  
‚ùå H√∂here Systemanforderungen  
‚ùå Weniger gelungene Ergebnisse als GPT-4  

---

## 5Ô∏è‚É£ Lokal Echo (Demo)

Der Local Echo Service ist f√ºr **Demo und Testzwecke** da.

- **Modell:** `echo`
- **Was macht es:** Repetiert deine Eingabe zur√ºck
- **N√ºtzlich f√ºr:** UI-Tests ohne externe APIs

---

## üîÑ Service Vergleich & Empfehlungen

### F√ºr Anf√§nger: **Gemini (Kostenlos)**
```
‚úÖ Kostenlos (60 calls/min)
‚úÖ Keine Kreditkarte
‚úÖ Einfaches Setup
‚úÖ Gute Qualit√§t
```

### F√ºr Profis: **Claude 3 Opus**
```
‚úÖ Beste Qualit√§t
‚úÖ L√§ngste Context (200K)
‚úÖ Exzellent f√ºr Code
‚úÖ Starke Compliance
```

### F√ºr Budget: **GPT-3.5 Turbo**
```
‚úÖ Sehr g√ºnstig
‚úÖ Schnell
‚úÖ Gute Qualit√§t
‚úÖ Gro√üe Community
```

### F√ºr Privatsph√§re: **Ollama Local**
```
‚úÖ Komplett offline
‚úÖ Kostenlos
‚úÖ Private Daten
‚úÖ Keine Rate Limits
‚ùå Braucht viele Ressourcen
```

---

## üîê Sicherheit & API-Keys

### Best Practices

1. **Niemals teilen**
   ```
   ‚ùå FALSCH: Poste deine API-Keys auf GitHub/Social Media
   ‚úÖ RICHTIG: Halte Keys privat/geheim
   ```

2. **In Umgebungsvariablen speichern** (f√ºr Produktion)
   ```
   # .env file
   OPENAI_API_KEY=sk-...
   CLAUDE_API_KEY=sk-ant-...
   ```

3. **Regelm√§√üig rotieren** (Schl√ºssel wechseln)
   - Deine Accounts ‚Üí API-Keys
   - Alte Keys l√∂schen
   - Neue Keys generieren

4. **Limits setzen** (im Provider-Dashboard)
   - Maximum monthly spend
   - Rate limits konfigurieren

### In dieser App

```typescript
// Keys werden mit einfacher Verschl√ºsselung im Browser
// gespeichert (localStorage)
// 
// F√ºr Produktion w√ºrde man verwenden:
// - Server-seitige Key-Speicherung
// - Environment Variables
// - Secrets Manager (AWS, Azure, etc.)
```

---

## üêõ Troubleshooting

### Allgemeine Probleme

| Fehler | Ursache | L√∂sung |
|--------|--------|--------|
| "Invalid API key" | Falscher Key | Pr√ºfe ob Key korrekt kopiert |
| "Network error" | Kein Internet | Pr√ºfe Internetverbindung |
| "401 Unauthorized" | Key abgelaufen | Generiere neuen Key |
| "Rate limit" | Zu viele Anfragen | Warte 1 Minute, versuche sp√§ter |
| "Token limit exceeded" | Text zu lang | Verk√ºrze Eingabe |

### Service-spezifische Probleme

**OpenAI:**
- Pr√ºfe Guthaben auf [platform.openai.com](https://platform.openai.com/account/billing/overview)
- API-Key in [Account Settings](https://platform.openai.com/account/api-keys)

**Claude:**
- Pr√ºfe Credits auf [console.anthropic.com](https://console.anthropic.com)
- API-Key in [Account Settings](https://console.anthropic.com/account/keys)

**Ollama:**
- Pr√ºfe ob Ollama server l√§uft: `curl http://localhost:11434/api/tags`
- Falls nicht: `ollama serve` im Terminal
- Pr√ºfe ob Modell heruntergeladen: `ollama ls`

---

## üìä Performance-Vergleich

```
Response Time (typisch):
  GPT-4: 5-10s (abh√§ngig von Load)
  GPT-3.5: 2-5s
  Claude: 3-7s
  Gemini: 2-4s
  Ollama: 5-30s (auf schwacher Hardware)
```

---

## üöÄ N√§chste Schritte

1. **W√§hle einen Service:**
   - Anf√§nger ‚Üí Gemini
   - Qualit√§t ‚Üí Claude oder GPT-4
   - Budget ‚Üí GPT-3.5 oder Ollama

2. **Hole dir API-Key:**
   - Folge der Setup-Anleitung oben

3. **Teste die Integration:**
   - Stelle eine Frage in der App
   - √úberpr√ºfe die Antwort

4. **Optimiere deine Settings:**
   - Temperature (Kreativit√§t)
   - System Prompt (Anweisung)
   - Modell (basierend auf Aufgabe)

---

## üìö Ressourcen

- **OpenAI Docs:** https://platform.openai.com/docs
- **Claude Docs:** https://docs.anthropic.com
- **Gemini Docs:** https://ai.google.dev
- **Ollama:** https://ollama.ai
- **Model Vergleich:** https://www.promptengineering.org/models

---

## üí¨ Support

Hast du Fragen oder Probleme?

1. **Siehe das Troubleshooting Kapitel oben**
2. **Pr√ºfe die Provider-Dokumentation (Links oben)**
3. **Kontaktiere den jeweiligen Service-Support:**
   - OpenAI: https://help.openai.com
   - Claude: https://support.anthropic.com
   - Google: https://support.google.com

---

*Letzte Aktualisierung: 2024*